[LOCAL]
spark.app.name = f1-racing-analysis
spark.jars.packages = org.apache.hadoop:hadoop-aws:3.3.6,io.delta:delta-spark_2.12:3.2.0,org.apache.spark:spark-sql-kafka-0-10_2.13:3.5.1
spark.hadoop.fs.s3a.endpoint = http://minio:9000
spark.hadoop.fs.s3a.access.key = root
spark.hadoop.fs.s3a.secret.key = password
spark.hadoop.fs.s3a.path.style.access = true
spark.hadoop.fs.s3a.impl = org.apache.hadoop.fs.s3a.S3AFileSystem
spark.sql.extensions = io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog = org.apache.spark.sql.delta.catalog.DeltaCatalog
spark.hadoop.hive.metastore.uris = thrift://hive-metastore:9083
spark.sql.warehouse.dir = s3a://metastore/spark-warehouse

[QA]
spark.app.name = sbit-qa
spark.jars.packages = org.apache.hadoop:hadoop-aws:3.3.6,io.delta:delta-spark_2.12:3.2.0,org.apache.spark:spark-sql-kafka-0-10_2.13:3.5.1
spark.hadoop.fs.s3a.endpoint = http://minio:9000
spark.hadoop.fs.s3a.access.key = root
spark.hadoop.fs.s3a.secret.key = password
spark.hadoop.fs.s3a.path.style.access = true
spark.hadoop.fs.s3a.impl = org.apache.hadoop.fs.s3a.S3AFileSystem
spark.sql.extensions = io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog = org.apache.spark.sql.delta.catalog.DeltaCatalog
spark.hadoop.hive.metastore.uris = thrift://hive-metastore:9083
spark.sql.warehouse.dir = s3a://metastore/spark-warehouse
spark.executor.cores = 5
spark.executor.memory = 10GB
spark.executor.memoryOverhead = 1GB
spark.executor.instances = 20
spark.sql.shuffle.partitions = 800
[PROD]
spark.app.name = sbdl
spark.jars.packages = org.apache.hadoop:hadoop-aws:3.3.6,io.delta:delta-spark_2.12:3.2.0,org.apache.spark:spark-sql-kafka-0-10_2.13:3.5.1
spark.hadoop.fs.s3a.endpoint = http://minio:9000
spark.hadoop.fs.s3a.access.key = root
spark.hadoop.fs.s3a.secret.key = password
spark.hadoop.fs.s3a.path.style.access = true
spark.hadoop.fs.s3a.impl = org.apache.hadoop.fs.s3a.S3AFileSystem
spark.sql.extensions = io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog = org.apache.spark.sql.delta.catalog.DeltaCatalog
spark.hadoop.hive.metastore.uris = thrift://hive-metastore:9083
spark.sql.warehouse.dir = s3a://metastore/spark-warehouse
spark.executor.cores = 5
spark.executor.memory = 10GB
spark.executor.memoryOverhead = 1GB
spark.executor.instances = 20
spark.sql.shuffle.partitions = 800

